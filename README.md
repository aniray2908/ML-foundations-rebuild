# ML Foundations Rebuild

A structured 6-week machine learning foundations reboot focused on mathematical maturity, statistical learning theory, and disciplined model evaluation.

This repository is not about collecting certificates.

It is about rebuilding core ML foundations through:
- Clear theory documentation
- Mathematical reasoning
- Structured experimentation
- Clean implementation

---

## Why This Repository Exists

The goal of this sprint is to:

- Strengthen linear algebra confidence
- Deepen statistical learning understanding
- Build disciplined model selection habits
- Transition from "fitting models" to "understanding generalization"
- Prepare for advanced ML, MLOps, and production systems

---

# Repository Structure

ML-foundations-rebuild/\
│\
├── linear_algebra/\
├── statistical_learning/\
├── mlops_pipeline/\
│\
├── requirements.txt\
└── README.md

---

## Week 1 – Linear Algebra Foundations

Topics covered:

- Matrix multiplication & transformations
- Eigenvalues and eigenvectors
- Singular Value Decomposition (SVD)
- Principal Component Analysis (PCA)

Focus:
Understanding how matrix operations drive machine learning models.

---

## Week 2 – Statistical Learning

Topics covered:

- Bias–Variance Tradeoff
- Linear Regression (statistical view)
- Multicollinearity
- Ridge & Lasso regularization
- Cross-validation (K-fold, LOOCV)
- AIC & AICc
- Hyperparameter tuning
- Structured model comparison

Implementation notebooks include:

- Bias–Variance visualization
- Ridge vs Lasso coefficient comparison
- Cross-validation tuning of Ridge
- OLS vs Ridge vs Lasso vs Random Forest comparison

Outcome:
Understanding generalization, model complexity, and disciplined evaluation.

---

# Installation

Clone the repository:

git clone https://github.com/aniray2908/ML-foundations-rebuild.git
cd ML-foundations-rebuild

Install dependencies:
pip install -r requirements.txt

---

# Key Learning Philosophy

This repository follows three principles:

1. Theory before tooling  
2. Derivation before automation  
3. Evaluation before optimization  

Model performance is not just about accuracy.
It is about understanding bias, variance, and generalization behavior.

---

# References

Primary sources used in this rebuild:

- James, Witten, Hastie, Tibshirani — *Introduction to Statistical Learning*
- Hastie, Tibshirani, Friedman — *The Elements of Statistical Learning*
- Stanford Statistical Learning Lectures
- Scikit-learn Documentation

---

# Next Steps

Upcoming sections will expand into:

- Evaluation metrics & interpretability
- Engineered ML pipelines
- Reproducible experimentation
- MLOps foundations

---

# Author

Anisha Ray  
